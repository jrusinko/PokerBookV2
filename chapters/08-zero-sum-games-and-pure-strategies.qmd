---
title: "Zero-Sum Games and Pure Strategies"
chapter-id: "ch08"
part: "Part III: Game Theory (Intro / Toy Models)"
poker-topics:
  - "11 Zero-Sum Interaction"
  - "12 Mixed Strategies"
applications:
  - "sports strategy (penalty kicks/play calling)"
  - "cybersecurity (attack–defense)"
  - "military strategy (adversarial planning)"
sidebar:
  lens: "History / ethics"
  title: "War, Games, and Human Cost"
  theme: "Game theory’s military origins and critiques of zero-sum framing that can dehumanize opponents or obscure moral stakes."
---
::: {.callout-note}
**Chapter at a glance**

- **Part:** Part III: Game Theory (Intro / Toy Models)
- **Poker topics:** 11 Zero-Sum Interaction, 12 Mixed Strategies
- **Beyond poker:** sports strategy (penalty kicks/play calling), cybersecurity (attack–defense), military strategy (adversarial planning)

:::

## Motivating Example

If you always bluff, you get snapped; if you never bluff, you get overfolded against. Randomizing feels irrational—but can be optimal.

**Guiding question.** Why would a rational strategy ever involve deliberate randomness?

- Situation: If you always bluff, you get snapped; if you never bluff, you get overfolded against. Randomizing feels irrational—but can be optimal.
- Why it matters: this introduces 11 Zero-Sum Interaction, 12 Mixed Strategies.


## Strategic Games Introduction


### Strategic Interaction

Game theory studies situations in which multiple decision-makers interact and the outcome for each depends on the actions of others.

Before introducing formal definitions, we begin with three canonical examples.



### Example 1: Rock–Paper–Scissors

There are two players. Each simultaneously chooses one element of the strategy set

$$
S_i = \{\text{Rock}, \text{Paper}, \text{Scissors}\}.
$$

The outcome is determined by the standard rules:

- Rock defeats Scissors,
- Scissors defeats Paper,
- Paper defeats Rock,
- Identical choices result in a tie.

Assign payoff $+1$ to a win, $-1$ to a loss, and $0$ to a tie.

The payoff matrix to Player I is

$$
A =
\begin{pmatrix}
0 & -1 & 1 \\
1 & 0 & -1 \\
-1 & 1 & 0
\end{pmatrix}.
$$

Player II’s payoff is $-A_{ij}$.

This is a simultaneous two–player zero–sum game.



### Example 2: The Prisoner’s Dilemma

Two players simultaneously choose between

$$
S_i = \{\text{Cooperate}, \text{Defect}\}.
$$

A possible payoff matrix (to Player I) is

$$
A =
\begin{pmatrix}
-1 & -4 \\
0 & -3
\end{pmatrix}.
$$

Here the total payoff

$$
u_1(s_1,s_2) + u_2(s_1,s_2)
$$

is not constant across outcomes. The game is therefore not zero–sum.

This example illustrates that strategic interaction need not be purely adversarial. Incentives may conflict without being perfectly opposed.



### Example 3: A Sequential Poker Decision

Consider a simplified river situation in heads-up poker. The pot is $P$. Player I acts first and chooses **bet** or **check**.

- If Player I checks, the hand proceeds directly to showdown.
- If Player I bets, Player II observes the bet and chooses **call** or **fold**.

Suppose that at showdown Player I wins with probability

$$
x = \Pr(\text{Player I wins at showdown}),
\qquad 0 \le x \le 1.
$$

Player I’s payoffs are:

- If checking:
  $$
  xP.
  $$

- If betting and Player II folds:
  $$
  P.
  $$

- If betting and Player II calls:
  $$
  x(P+B) - (1-x)B.
  $$

Unlike the previous examples, this game is sequential. Player II’s action depends on observing Player I’s move. A strategy must therefore specify behavior conditional on earlier actions.



### What These Examples Share

Despite their differences, each example has common structural elements:

- A set of players,
- A set of possible actions (or strategies) for each player,
- A rule that assigns a payoff to every possible combination of actions.

In Rock–Paper–Scissors and the Prisoner’s Dilemma, actions are chosen simultaneously.

In the poker example, actions occur in sequence, and later choices depend on earlier ones.

The unifying feature is interdependence:

> Each player’s payoff depends not only on their own choice, but on the choices of others.

This distinguishes games from optimization against nature.

In optimization under uncertainty, one chooses $s$ to maximize an expected value such as

$$
\mathbb{E}[X(s)],
$$

where uncertainty arises from random processes. Nature does not adapt.

In a game, by contrast, each participant solves an optimization problem whose objective depends on the simultaneous or sequential optimization of others.



### Formal Definition (Finite Simultaneous Game)

We now abstract the structure illustrated above.

A **finite game** consists of:

1. A finite set of players indexed by $1,\dots,N$.
2. For each player $i$, a finite strategy set $S_i$.
3. For each player $i$, a payoff function
   $$
   u_i : S_1 \times \cdots \times S_N \to \mathbb{R}.
   $$

An element

$$
(s_1,\dots,s_N) \in S_1 \times \cdots \times S_N
$$

is called a **strategy profile**.

The value $u_i(s_1,\dots,s_N)$ represents the payoff to player $i$ when that strategy profile is played.

In simultaneous games, this structure is complete.

In sequential games, the strategy sets consist not merely of single actions but of complete contingent plans — functions defined on possible histories of play. The payoff function is defined on terminal histories rather than directly on single actions.

The next section formalizes this distinction more precisely.

### Elements of a Game

A game is determined not merely by the presence of multiple decision-makers, but by a precise specification of how their decisions interact. We now describe the structural components that define a game.

#### Players

The **players** are the decision-making agents in the model.

Formally, let
$$
\mathcal{N} = \{1,2,\dots,N\}
$$
denote the finite set of players.

Each player is assumed to be rational in the sense that they seek to maximize their own payoff, given their beliefs about the actions of others.

In a heads-up poker hand, for example, $\mathcal{N} = \{1,2\}$ consists of the bettor and the defender. In a multiway pot, $\mathcal{N}$ would contain more elements.

The number of players fundamentally shapes the structure of the game: two-player games often exhibit different mathematical properties from games with three or more participants.

#### Strategy Sets

For each player $i \in \mathcal{N}$, we specify a finite set $S_i$ of available actions, called the **strategy set** of player $i$.

An element $s_i \in S_i$ is called a **pure strategy**.

The term “strategy” may refer to a single move or to a complete plan of action, depending on the timing structure of the game (which we describe below).

In a simplified river poker model:

- Player I might have $S_1 = \{\text{bet}, \text{check}\}$.
- Player II might have $S_2 = \{\text{call}, \text{fold}\}$.

The strategy sets specify what actions are permitted within the model. They are modeling choices, not empirical descriptions of all human behavior.

#### Strategy Profiles

A **strategy profile** is a tuple
$$
(s_1, \dots, s_N) \in S_1 \times \cdots \times S_N.
$$

It specifies one strategy choice for every player.

The Cartesian product
$$
S_1 \times \cdots \times S_N
$$
is the set of all possible strategy  generated by players’ choices.



#### Payoff Functions

For each player $i$, a **payoff function**
$$
u_i : S_1 \times \cdots \times S_N \to \mathbb{R}
$$
assigns a real number to every strategy profile.

The number $u_i(s_1,\dots,s_N)$ represents the payoff to player $i$ when the strategy profile $(s_1,\dots,s_N)$ is played.

Payoffs may represent:

- Monetary winnings,
- Utility,
- Points,
- Or any quantitative measure of preference.


The payoff function encodes the incentives of the game. Once specified, the strategic problem becomes purely mathematical.

#### Timing Structure

The **timing structure** describes when decisions are made and in what order.

Two principal types:

- **Simultaneous-move games**: all players choose without observing others’ actions.
- **Sequential games**: players move in a specified order, possibly observing previous moves.

In a single betting round of poker, one player acts first and the other responds. Across multiple betting rounds, the timing structure becomes more complex.

The timing structure determines whether strategies are single actions or complete contingent plans.


#### Information Structure

The **information structure** of a game specifies what each player knows when choosing a strategy.

Key questions include:

- Do players observe each other’s actions?
- Do players know the payoff functions?
- Do players possess private information?

In simultaneous-move games, players choose without observing the actions of others. In sequential games, later players may observe earlier moves.

In poker, players typically do not observe their opponents’ private cards. This creates informational asymmetry, which profoundly affects strategic reasoning.

Information structure determines what strategies are meaningful and what beliefs are required.

Together, the players, strategy sets, payoff functions, information structure, and timing structure fully specify a game.

Once these elements are fixed, the analysis proceeds by studying how rational players reason within that structure.

## II. A Taxonomy of Games

The definition of a game specifies its formal components: players, strategy sets, payoffs, information, and timing. But games differ profoundly in structure. Some involve pure competition; others allow for cooperation. Some are resolved in a single move; others unfold over time. Some contain no randomness; others incorporate chance.

To analyze games effectively, we must classify them according to structural features that determine their mathematical behavior.



We begin with the most fundamental distinction: the relationship among players’ payoffs.

### Zero–Sum vs. Non–Zero–Sum

The nature of strategic interaction depends critically on how the players’ payoffs are related.

#### Zero–Sum Games

A two-player game is called **zero–sum** if, for every strategy profile $(s_1,s_2)$,

$$
u_1(s_1,s_2) + u_2(s_1,s_2) = 0.
$$

In such games, one player’s gain is exactly the other player’s loss.

All interests are strictly opposed. There is no possibility of mutual benefit. Any increase in one player’s payoff necessarily decreases the other’s payoff by the same amount.

In this setting, it is sufficient to describe a single payoff function. If we define

$$
u(s_1,s_2) = u_1(s_1,s_2),
$$

then Player II’s payoff is simply $-u(s_1,s_2)$.

Zero–sum structure leads to a particularly clean mathematical theory, culminating in the minimax theorem.

#### Constant–Sum Games

A game is **constant–sum** if there exists a constant $C$ such that

$$
u_1(s_1,s_2) + u_2(s_1,s_2) = C
$$

for all strategy profiles.

Constant–sum games are strategically equivalent to zero–sum games. Indeed, if we define

$$
\tilde{u}_1(s_1,s_2) = u_1(s_1,s_2) - \frac{C}{2},
$$

then

$$
\tilde{u}_1(s_1,s_2) + \tilde{u}_2(s_1,s_2) = 0.
$$

Thus, constant–sum games differ from zero–sum games only by an affine transformation of payoffs.

#### General–Sum Games

A game is **general–sum** (or non–zero–sum) if the sum

$$
u_1(s_1,s_2) + u_2(s_1,s_2)
$$

varies across strategy profiles.

In such games, players’ interests are not perfectly opposed. Some outcomes may benefit both players relative to others. Conflict and cooperation may coexist.

This distinction has profound consequences.

In zero–sum games:
- The interaction is one of pure conflict.
- One player’s objective is to minimize the other’s maximum possible gain.
- Equilibrium is characterized by minimax reasoning.

In general–sum games:
- Players may have incentives to coordinate.
- Equilibrium concepts must account for mutual best responses rather than pure opposition.
- The mathematical structure becomes more complex.

Throughout this chapter, we focus on finite two-player zero–sum games. Their structural simplicity allows us to develop a complete and elegant theory before turning to more general strategic environments.

### Simultaneous vs. Sequential Games

Games differ not only in payoffs, but in timing.

The distinction between simultaneous and sequential play changes the internal mathematical structure of the game.



#### Simultaneous-Move Games

In a finite simultaneous game:

- Each player $i$ has a finite strategy set $S_i$.
- A strategy is a single action.
- A strategy profile is an element
  $$
  (s_1, \dots, s_N) \in S_1 \times \cdots \times S_N.
  $$
- The payoff function is
  $$
  u_i : S_1 \times \cdots \times S_N \to \mathbb{R}.
  $$

Timing does not explicitly appear in the structure because players choose without observing the actions of others.

In the two-player case, this structure is naturally represented by a payoff matrix.

Analysis proceeds by examining best responses within this product space.



#### Sequential Games

In a sequential game, actions occur over time. Later players may observe earlier moves before acting.

To formalize this, we introduce **histories**.

A history is a finite sequence of actions:

$$
h = (a_1, a_2, \dots, a_k).
$$

The set of all histories is denoted by $H$, and the empty history $\varnothing$ represents the start of the game.

A subset $Z \subset H$ consists of **terminal histories**, at which the game ends.

Payoffs are assigned to terminal histories:

$$
u_i : Z \to \mathbb{R}.
$$

Each nonterminal history $h \in H \setminus Z$ is assigned to a player $P(h)$ who moves after that history.  
At that point, the player chooses an action from a finite set $A_i(h)$.

Thus the game is represented as a tree of histories.



#### Strategies in Sequential Games

A pure strategy must specify what a player will do at every history where they are called upon to act.

Let

$$
H_i = \{ h \in H \setminus Z : P(h) = i \}.
$$

Then a pure strategy for player $i$ is a function

$$
s_i : H_i \to A
$$

such that

$$
s_i(h) \in A_i(h).
$$

Thus, unlike simultaneous games where a strategy is a single action, in sequential games a strategy is a **complete contingent plan**.



#### Information Structure

If a player cannot distinguish between certain histories, those histories form an **information set**.

Let $\mathcal{I}_i$ denote the collection of information sets for player $i$.

A strategy must assign the same action at all histories within the same information set.  
Equivalently,

$$
s_i : \mathcal{I}_i \to A.
$$

Information therefore restricts which contingent plans are admissible.



#### Strategic Form vs. Extensive Form

Every finite sequential game can be reduced to a strategic-form representation:

$$
u_i : S_1 \times \cdots \times S_N \to \mathbb{R},
$$

where each $S_i$ is the set of admissible contingent plans.

However, the internal structure differs:

- In simultaneous games, strategies are elements of small finite sets.
- In sequential games, strategies are functions defined on histories or information sets.
- The size of $S_i$ may grow exponentially with the depth of the tree.

This structural difference shapes analysis.

Simultaneous games are naturally analyzed using matrices and best-response geometry.

Sequential games invite analysis through backward reasoning along the tree.

The taxonomy of games is therefore not merely descriptive.  
It determines the mathematical tools required for equilibrium analysis.


### Deterministic vs. Stochastic Games

Games also differ in whether randomness enters the model externally.

#### Deterministic Games

A game is **deterministic** if the outcome is determined entirely by the players’ strategy choices.

Formally, once a strategy profile
$$
(s_1, \dots, s_N)
$$
is selected, the payoff vector
$$
(u_1(s_1,\dots,s_N), \dots, u_N(s_1,\dots,s_N))
$$
is fixed.

There are no additional random events influencing the result.

In such games, uncertainty arises only from the strategic choices of other players.

#### Games with Chance Nodes

In many strategic environments, outcomes depend not only on player choices but also on random events.

These games include **chance nodes**, representing moves by “nature.” At such nodes, an outcome is selected according to a specified probability distribution.

Formally, one may model this by enlarging the strategy profile to include a random variable $Z$ governed by a known distribution, so that payoffs take the form
$$
u_i(s_1,\dots,s_N, Z).
$$

Expected payoffs are then computed by integrating over the randomness of $Z$.

Poker provides a natural example. The dealing of cards is a stochastic event. Even if players’ strategies are fixed, the realized payoff depends on the random shuffle.

#### Randomization by Players vs. Randomness Imposed by Nature

It is crucial to distinguish two conceptually different sources of randomness:

1. **Randomness imposed by nature**, such as shuffled cards or dice rolls.
2. **Randomization chosen by players**, such as mixing between strategies.

In the first case, randomness is external to the players’ control. It is part of the environment.

In the second case, randomness is a deliberate strategic device. A player may choose a probability distribution over actions in order to prevent exploitation.

Mathematically, these two types of randomness are treated differently:

- Exogenous randomness affects the payoff function directly.
- Strategic randomization enlarges the strategy set itself.

This distinction becomes central when we introduce mixed strategies. There, probability is not modeling ignorance about events, but representing a conscious strategic choice.

### Fixed Horizon vs. Random Horizon

Games may also differ in how long they last.

The horizon of a game refers to the number of decision stages before termination.



#### Fixed Horizon

In a fixed-horizon game, the number of stages is predetermined.

For example:

- A poker hand has a finite sequence of betting rounds.
- A chess game ends when a terminal position is reached.
- A bargaining game may allow exactly $T$ offers.

Mathematically, we may represent such a game as a sequential game whose histories have bounded length. If $T$ denotes the maximum number of stages, then every terminal history satisfies

$$
\text{length}(h) \le T.
$$

A related formulation is a **repeated game**: the same stage game is played $T$ times.

Let $G$ be a finite strategic-form game with payoff functions $u_i$.  
The $T$-period repeated game consists of:

- The same players,
- The same stage strategy sets in each period,
- Histories consisting of sequences of past action profiles,
- Payoffs given by an aggregation such as

  $$
  U_i = \sum_{t=1}^T u_i(s^t),
  $$

  where $s^t$ denotes the strategy profile played in period $t$.

Thus a fixed-horizon repeated game can be represented as a single sequential game whose histories record past play.

The mathematical distinction lies not in the players or payoffs, but in how histories accumulate across stages.



#### Infinite Horizon

In an infinite-horizon game, there is no predetermined terminal stage.

Histories may be arbitrarily long:

$$
h = (a_1, a_2, a_3, \dots).
$$

To ensure well-defined payoffs, one typically introduces a discount factor $0 < \delta < 1$ and defines

$$
U_i = \sum_{t=1}^\infty \delta^{t-1} u_i(s^t).
$$

Infinite horizon models are central in economics and repeated strategic interaction, where long-term incentives influence current behavior.



#### Random Horizon

In a random-horizon game, termination occurs probabilistically.

At each stage, the game continues with probability $\delta$ and ends with probability $1-\delta$.

The expected payoff can then be written as

$$
U_i = \mathbb{E}\left[ \sum_{t=1}^{\tau} u_i(s^t) \right],
$$

where $\tau$ is a random stopping time.

Notably, the random-horizon model with continuation probability $\delta$ is mathematically equivalent to the infinite-horizon discounted model above.



#### Conceptual Distinction

A fixed-horizon multi-stage game and a $T$-period repeated game of a single stage game can be represented within the same formal framework:

- Histories record prior actions,
- Strategies are functions defined on histories,
- Payoffs aggregate across stages.

The difference is interpretive rather than structural:

- In a multi-stage game, stages may differ in available actions.
- In a repeated game, each stage is strategically identical.

In both cases, horizon length affects incentives.  
When the end is known, backward reasoning may simplify behavior.  
When continuation is uncertain or infinite, future consequences may sustain cooperation or deterrence.

Thus horizon structure alters not the definition of a game, but the strategic logic that emerges from it.

### Information Structure in Games

Games differ not only in payoffs and timing, but in what players know.

To avoid confusion, we separate three distinct sources of uncertainty:

1. **Stochastic uncertainty** — randomness generated by nature.
2. **Imperfect information** — limited observation of past actions.
3. **Incomplete information** — uncertainty about the underlying structure of the game.

These are conceptually and mathematically different.



#### Stochastic Structure (Nature)

Many games include exogenous randomness:

- Card deals in poker,
- Dice rolls,
- Random shocks in economic models.

Formally, certain histories are assigned to **nature**.  
If $P(h) = \text{Nature}$, then the next action is drawn from a known probability distribution

$$
\pi(\cdot \mid h).
$$

All players know this distribution, and this knowledge is common knowledge.

Randomness therefore affects expected payoffs, but it does not by itself create incomplete information.

A game may be stochastic and still have complete information.



#### Perfect vs. Imperfect Information

This distinction concerns what players observe about the history of play.

A sequential game has **perfect information** if, whenever a player moves, they observe the entire prior history.

Equivalently, every information set contains a single history.

Chess is a perfect-information game.

A game has **imperfect information** if some player moves without observing all prior actions.

Formally, some information set contains multiple histories.

Poker is imperfect-information because players do not observe opponents’ private cards.

Imperfect information alters the structure of admissible strategies, since a strategy must assign the same action at all histories within an information set.



#### Complete vs. Incomplete Information

This distinction concerns knowledge of the game’s primitives.

A game has **complete information** if:

- All players know the strategy sets,
- All players know the payoff functions,
- All players know the probability laws governing nature,
- This knowledge is common knowledge.

In standard poker:

- The rules are known,
- The payoff structure is known,
- The distribution of cards is known.

Although players do not know opponents’ private cards, the game is one of complete information. The uncertainty is stochastic and observational, not structural.

A game has **incomplete information** if at least one player lacks knowledge about:

- Another player’s payoff function,
- Another player’s available strategies,
- Or some underlying parameter of the model.

In such cases, players must form beliefs not only about actions, but about the structure generating those actions.



#### Independence of the Distinctions

These categories are logically independent.

A game may be:

- Perfect and complete (e.g., chess),
- Imperfect and complete (e.g., standard poker),
- Perfect and incomplete (e.g., bargaining with unknown valuations but observable actions),
- Imperfect and incomplete (e.g., poker with private risk preferences).

Randomness, observation, and structural knowledge operate at different levels of the model.

Maintaining these distinctions is essential.  
Random events affect expected value.  
Imperfect information restricts admissible strategies.  
Incomplete information enlarges the strategic problem by introducing beliefs about unknown parameters.


Later chapters will formalize incomplete information using type spaces and Bayesian reasoning. For now, it is enough to recognize that these are distinct dimensions along which games vary.

### Cooperative vs. Competitive Games

Games may also be classified according to whether players are permitted to coordinate and form binding agreements.

#### Competitive (Noncooperative) Games

In a competitive or **noncooperative** game:

- Each player chooses strategies independently.
- Agreements, if discussed, are not enforceable.
- The outcome is determined solely by the strategy profile
  $$
  (s_1, \dots, s_N).
  $$

Most of this chapter studies competitive games.  
Poker, Rock–Paper–Scissors, and the Prisoner’s Dilemma (in its standard formulation) are noncooperative games.

The mathematical framework is based on:

- Strategy sets,
- Payoff functions,
- Equilibrium defined through mutual best responses.



#### Cooperative Games

In a **cooperative** game:

- Players may form binding agreements.
- Coalitions may form.
- The central question becomes how collective gains are distributed among members.

Rather than focusing on individual strategy profiles, cooperative game theory studies:

- The value generated by coalitions,
- Stability of agreements,
- Allocation rules.

Formally, a cooperative game is often described by a function

$$
v : 2^N \to \mathbb{R},
$$

where $v(S)$ represents the value that coalition $S \subseteq N$ can guarantee for itself.




#### Poker Perspective

Poker is modeled as a noncooperative game: each player acts independently to maximize their own expected value.

However, tournament poker reveals the boundary between cooperative and competitive modeling. If two players agree to soft-play one another or share prize money regardless of finish, they are effectively forming a coalition. Such coordination alters the payoff structure and invalidates the standard noncooperative analysis.

This illustrates an important modeling principle:

The distinction between cooperative and competitive games is not about whether cooperation is possible in practice. It concerns whether cooperation is built into the mathematical model.


This chapter focuses on competitive (noncooperative) games.  
Cooperative game theory forms a parallel and equally rich branch of the subject.



## III. Finite Two–Player Simultaneous Zero–Sum Games

We now restrict attention to a specific class of games whose structure allows a complete mathematical theory: finite, two-player, simultaneous-move, zero–sum games.

### Formal Definition

A **finite two–player zero–sum game** consists of:

1. Two players, labeled Player I and Player II.
2. Finite strategy sets
   $$
   S_1 = \{s_1^1, \dots, s_1^m\}, 
   \quad
   S_2 = \{s_2^1, \dots, s_2^n\}.
   $$
3. A payoff function
   $$
   u : S_1 \times S_2 \to \mathbb{R}
   $$
   representing the payoff to Player I.

The payoff to Player II is defined by
$$
- u(s_1, s_2).
$$

Thus, for every strategy pair $(s_1, s_2)$,
$$
u_1(s_1,s_2) + u_2(s_1,s_2) = 0.
$$

The game is simultaneous: both players choose their strategies without observing the choice of the other.

Because the strategy sets are finite, the Cartesian product
$$
S_1 \times S_2
$$
contains finitely many outcomes.

Once the function $u$ is specified, the strategic problem is completely determined.

### Matrix Representation

Since the strategy sets are finite, the game may be represented by a matrix.

Index Player I’s strategies as
$$
s_1^1, \dots, s_1^m,
$$
and Player II’s strategies as
$$
s_2^1, \dots, s_2^n.
$$

Define the matrix
$$
A \in \mathbb{R}^{m \times n}
$$
by
$$
A_{ij} = u(s_1^i, s_2^j).
$$

Interpretation:

- Each **row** corresponds to a strategy of Player I.
- Each **column** corresponds to a strategy of Player II.
- The entry $A_{ij}$ is the payoff to Player I when Player I chooses $s_1^i$ and Player II chooses $s_2^j$.

Player II’s payoff is $-A_{ij}$.

Thus, a finite two–player zero–sum game is completely characterized by a real matrix.

The analysis of such games reduces to studying the strategic properties of this matrix.

### Worked Example: Building the Payoff Matrix for the Three-Card Poker Game

We now illustrate, in full detail, how a payoff matrix is constructed when the game includes private cards and simultaneous betting decisions.

#### Game Rules

- Deck: $\{A,K,Q\}$ with $A>K>Q$.
- Nature deals one card to each player **without replacement**, so the six ordered deals are
  $$
  (A,K),(A,Q),(K,A),(K,Q),(Q,A),(Q,K),
  $$
  each with probability $1/6$.
- After seeing their own card, each player simultaneously chooses either **Bet** ($B$) or **No bet** ($N$).
- Payoffs to Player I are:

  1. If both choose $N$, go to showdown:
     - higher card wins $+1$,
     - lower card loses $-1$.

  2. If exactly one player bets, the bettor wins $+1$ and the other loses $-1$.

  3. If both bet, go to showdown:
     - higher card wins $+2$,
     - lower card loses $-2$.

This is a two-player zero–sum game.



#### Step 1: Pure Strategies Are Contingent Plans

A pure strategy is not a card. A card is chosen by nature.

A pure strategy for a player is a rule that specifies what to do holding each possible card:

$$
s:\{A,K,Q\}\to\{N,B\}.
$$

Since there are 2 choices for each of 3 cards, there are

$$
2^3 = 8
$$

pure strategies.

We encode a strategy by a triple indicating the action with $(A,K,Q)$, in that order.
For example:

- $NBN$ means: no bet with $A$, bet with $K$, no bet with $Q$.
- $BBB$ means: bet with all cards.

We will use the ordering:

$$
NNN,\ NNB,\ NBN,\ NBB,\ BNN,\ BNB,\ BBN,\ BBB.
$$

Let these be denoted
$$
s^1, s^2, \dots, s^8.
$$



#### Step 2: Define the Payoff Matrix Entrywise

The payoff matrix $A$ is an $8\times 8$ matrix where

$$
A_{ij} = u(s^i, s^j)
$$

is the **expected payoff to Player I** when Player I uses strategy $s^i$ and Player II uses strategy $s^j$.

Because the cards are dealt randomly, each entry is an expectation over the six feasible deals:

$$
A_{ij}
=
\frac{1}{6}
\sum_{(c_1,c_2)}
\text{Payoff}_I\big(c_1,c_2;\ s^i(c_1),\ s^j(c_2)\big),
$$

where the sum runs over

$$
(A,K),(A,Q),(K,A),(K,Q),(Q,A),(Q,K).
$$

Notice what has happened structurally:

- The *impossible* outcomes $(A,A)$, $(K,K)$, $(Q,Q)$ never appear.
- They are not assigned payoff $0$.
- They simply have probability $0$ and are absent from the expectation.



#### Step 3: Compute One Matrix Entry Explicitly

Compute $A_{1,6}$ where:

- Player I uses $s^1 = NNN$ (never bets),
- Player II uses $s^6 = BNB$ (bets with $A$, does not bet with $K$, bets with $Q$).

We evaluate Player I’s payoff deal by deal.

1. Deal $(A,K)$:
   - I holds $A$ and plays $N$.
   - II holds $K$ and plays $N$.
   - Both $N$ $\Rightarrow$ showdown, $A$ wins.
   - Payoff to I: $+1$.

2. Deal $(A,Q)$:
   - I: $A\mapsto N$.
   - II: $Q\mapsto B$.
   - Exactly one bet (II bets) $\Rightarrow$ I loses.
   - Payoff to I: $-1$.

3. Deal $(K,A)$:
   - I: $K\mapsto N$.
   - II: $A\mapsto B$.
   - II bets alone $\Rightarrow$ I loses.
   - Payoff to I: $-1$.

4. Deal $(K,Q)$:
   - I: $K\mapsto N$.
   - II: $Q\mapsto B$.
   - II bets alone $\Rightarrow$ I loses.
   - Payoff to I: $-1$.

5. Deal $(Q,A)$:
   - I: $Q\mapsto N$.
   - II: $A\mapsto B$.
   - II bets alone $\Rightarrow$ I loses.
   - Payoff to I: $-1$.

6. Deal $(Q,K)$:
   - I: $Q\mapsto N$.
   - II: $K\mapsto N$.
   - Both $N$ $\Rightarrow$ showdown, $K$ wins.
   - Payoff to I: $-1$.

Sum:
$$
(+1) + (-1)+(-1)+(-1)+(-1)+(-1) = -4.
$$

Average over 6 equally likely deals:
$$
A_{1,6} = -\frac{4}{6} = -\frac{2}{3}.
$$



#### Step 4: The Full Payoff Matrix

With the strategy ordering

$$
NNN,\ NNB,\ NBN,\ NBB,\ BNN,\ BNB,\ BBN,\ BBB,
$$

the payoff matrix to Player I is

$$
A=\frac{1}{6}
\begin{pmatrix}
 0 & -4 & -2 & -6 &  0 & -4 & -2 & -6\\
 4 &  0 & -1 & -5 &  1 & -3 & -4 & -8\\
 2 &  1 &  0 & -1 & -1 & -2 & -3 & -4\\
 6 &  5 &  1 &  0 &  0 & -1 & -5 & -6\\
 0 & -1 &  1 &  0 &  0 & -1 &  1 &  0\\
 4 &  3 &  2 &  1 &  1 &  0 & -1 & -2\\
 2 &  4 &  3 &  5 & -1 &  1 &  0 &  2\\
 6 &  8 &  4 &  6 &  0 &  2 & -2 &  0
\end{pmatrix}.
$$

Because the game is symmetric and zero–sum, Player II’s payoff matrix is $-A^T$ if we switch player roles, and the expected payoff to Player II is always $-u_1$.



#### What This Example Illustrates

This example makes precise the relationship between:

- **randomness** (the deal of cards),
- **strategies** (contingent betting rules),
- **payoff matrices** (expected value over feasible deals).

The payoff matrix is not indexed by card outcomes.  
It is indexed by strategies.

Card incompatibilities are handled at the probability level: impossible deals have probability $0$ and do not appear in the expectation.

### Dominated Strategies

Before analyzing best responses and security levels, we simplify games by eliminating strategies that are never rational to play.

#### Definition (Strict Dominance)

Let $A$ be the payoff matrix for a two-player zero–sum game.

A row $i$ is **strictly dominated** by row $i'$ if

$$
A_{i'j} > A_{ij}
\quad
\text{for all } j.
$$

That is, regardless of what Player II does, strategy $i'$ yields a strictly higher payoff than strategy $i$.

In this case, strategy $i$ can never be optimal and may be removed from the game.

Similarly, a column $j$ is strictly dominated by column $j'$ if

$$
A_{ij'} < A_{ij}
\quad
\text{for all } i.
$$

Since Player II minimizes Player I’s payoff, a dominated column always gives Player I a larger payoff and is therefore irrational for Player II.



#### Weak Dominance

Row $i$ is **weakly dominated** by row $i'$ if

$$
A_{i'j} \ge A_{ij}
\quad
\text{for all } j,
$$

with strict inequality for at least one $j$.

Weakly dominated strategies are never better and sometimes worse.

In zero–sum games, strictly dominated strategies may be safely eliminated without affecting equilibrium analysis. Weak dominance requires more care but often provides useful simplification.



### Example: Dominance in the Three-Card Poker Game

Recall that pure strategies are encoded as triples indicating actions with $(A,K,Q)$:

$$
NNN,\ NNB,\ NBN,\ NBB,\ BNN,\ BNB,\ BBN,\ BBB.
$$

Consider the strategy $NNN$, which never bets.

Now compare it with $BNN$, which differs only in betting with $A$.

For every possible opponent strategy:

- When holding $A$, betting strictly improves payoff (it either wins uncontested or doubles winnings at showdown).
- With $K$ and $Q$, both strategies behave identically.

Thus for every column $j$,

$$
A_{BNN,j} \ge A_{NNN,j},
$$

with strict inequality for some $j$.

Therefore:

> $NNN$ is weakly dominated by $BNN$.

Intuitively, refusing to bet with the highest card sacrifices value without ever providing protection.



Similarly, any strategy that fails to bet with $A$ is weakly dominated by the identical strategy that *does* bet with $A$.

Thus, rational play restricts attention to strategies that always bet with $A$.

This observation reduces the strategic space from eight pure strategies to four:

$$
BNN,\ BNB,\ BBN,\ BBB.
$$

The game becomes structurally simpler before any equilibrium analysis begins.



### Conceptual Role of Dominance

Dominated strategies represent actions that are inferior regardless of the opponent’s behavior.

Eliminating them:

- Reduces the size of the game,
- Clarifies the strategic structure,
- Sharpens best-response analysis.

In poker terms, a dominated strategy is a betting rule that leaves money on the table no matter how the opponent plays.

The study of equilibrium begins only after clearly irrational strategies are removed.

### Best Responses (Reduced Game)

After eliminating dominated strategies, each player has four remaining pure strategies:

$$
BNN,\ BNB,\ BBN,\ BBB.
$$

These are the strategies that always bet with $A$ and vary behavior with $K$ and $Q$.

Let $A$ now denote the reduced $4 \times 4$ payoff matrix obtained by restricting the original matrix to these strategies.

Rows correspond to Player I and columns to Player II in the order

$$
BNN,\ BNB,\ BBN,\ BBB.
$$

Suppose Player II chooses column $j$.

Player I’s optimal pure response is any row index $i$ that maximizes

$$
A_{ij}.
$$

Thus Player I seeks

$$
\max_i A_{ij}.
$$

Similarly, if Player I chooses row $i$, Player II seeks to minimize Player I’s payoff:

$$
\min_j A_{ij}.
$$

Because the game is zero–sum, the players optimize opposing objectives over the same matrix.



### Example: A Best Response in the Reduced Game

Suppose Player II adopts the strategy $BNN$ (bet only with $A$).

In the reduced matrix, the corresponding column is

$$
\frac{1}{6}
\begin{pmatrix}
0 \\
1 \\
-1 \\
0
\end{pmatrix}.
$$

The largest entry is $1/6$, achieved by the strategy $BNB$.

Thus, if Player II bets only with $A$, Player I’s best response is to bet with $A$ and $Q$, but not with $K$.

The strategic adjustment now concerns bluffing frequency rather than whether to bet with $A$.



## Maximin and Minimax (Reduced Game)

Best responses describe local reactions.  
We now evaluate global security levels in the reduced matrix.

### Maximin

Player I evaluates each row by its worst outcome:

$$
\min_j A_{ij}.
$$

Then selects

$$
\max_i \min_j A_{ij}.
$$

For the reduced matrix, the row minima (scaled by $1/6$) are:

$$
\begin{array}{c|c}
\text{Strategy} & \min_j A_{ij} \\
\hline
BNN & -\frac{1}{6} \\
BNB & -\frac{2}{6} \\
BBN & -\frac{1}{6} \\
BBB & -\frac{2}{6}
\end{array}
$$

Thus

$$
\max_i \min_j A_{ij}
=
-\frac{1}{6}.
$$



### Minimax

Player II evaluates each column by

$$
\max_i A_{ij},
$$

and chooses

$$
\min_j \max_i A_{ij}.
$$

For the reduced matrix, the smallest column maximum equals

$$
\frac{1}{6}.
$$

Thus

$$
\min_j \max_i A_{ij}
=
\frac{1}{6}.
$$



### Fundamental Inequality

For every finite matrix $A$,

$$
\max_i \min_j A_{ij}
\;\le\;
\min_j \max_i A_{ij}.
$$

In the reduced poker matrix,

$$
-\frac{1}{6}
<
\frac{1}{6}.
$$

The inequality is strict.



## Saddle Points

A pair $(i^*, j^*)$ is a **saddle point** if

$$
A_{i^* j} \le A_{i^* j^*} \le A_{i j^*}
\quad
\text{for all } i, j.
$$

Equivalently, the entry is:

- The smallest value in its row,
- The largest value in its column.

If a saddle point exists, then

$$
\max_i \min_j A_{ij}
=
\min_j \max_i A_{ij}.
$$



## Absence of a Saddle Point

In the reduced three-card poker game,

$$
\max_i \min_j A_{ij}
=
-\frac{1}{6}
\quad
<
\quad
\frac{1}{6}
=
\min_j \max_i A_{ij}.
$$

Therefore:

- No saddle point exists.
- No pure strategy stabilizes the game.
- Every deterministic betting rule (even after removing dominated ones) can be exploited.

The strategic tension now lies entirely in how frequently players bluff with $Q$ or value-bet with $K$.

This structural failure of pure strategies motivates enlarging the strategy space.

### 3.X  A Sequential Zero–Sum Game: Extended Three-Card Poker

The previous example in this chapter considered a simultaneous-move matrix game.  
We now examine a **sequential** zero–sum game and show how it can be converted to normal form and simplified by dominance.

The purpose is structural: to illustrate how a game tree generates a payoff matrix, and how dominance can dramatically reduce its size before any minimax computation is attempted.


  
  ## The Game
  
  Let the deck consist of three cards
\[
  Q<K<A.
  \]
One card is dealt uniformly at random to each player without replacement.  
Each player antes 1 chip, so the pot begins at 2.

The betting proceeds sequentially:
  
  1. **Player 1 acts first**:  
  - Check, or  
- Bet 2.

2. If Player 1 bets, **Player 2** chooses:  
  - Call, or  
- Fold.

3. If Player 1 checks, **Player 2** chooses:  
  - Check, or  
- Bet 2.

If Player 2 bets, Player 1 then chooses Call or Fold.

If both players check, or if a bet is called, the higher card wins at showdown.


  
  ## Payoffs (net chips to Player 1)
  
  - **Check–check:** pot = 2; winner nets \(+1\), loser nets \(-1\).
- **Bet–fold:** pot = 4; bettor nets \(+1\), folder nets \(-1\).
- **Bet–call:** pot = 6; winner nets \(+3\), loser nets \(-3\).

The game is finite and zero–sum.


  
  ## Step 1. Normal form with reduced Player 1 strategies
  
  To convert the sequential game to a simultaneous (normal-form) game, we replace moves by complete contingent plans.

For **Player 1**, a reduced pure strategy is a function
\[
  s_1:\{Q,K,A\}\to\{B,C,F\},
  \]
where:
  
  - \(B\): bet immediately;
- \(C\): check, then call if facing a bet;
- \(F\): check, then fold if facing a bet.

This reduction is valid because if Player 1 bets initially, no later call/fold decision occurs. Hence Player 1 has
\[
  3^3=27
  \]
pure strategies.

For **Player 2**, a pure strategy consists of two maps:
  \[
    r_2:\{Q,K,A\}\to\{\text{Call},\text{Fold}\}
    \]
(when facing a bet from Player 1), and
\[
  a_2:\{Q,K,A\}\to\{\text{Bet},\text{Check}\}
  \]
(after Player 1 checks).

Thus Player 2 has \(2^3\cdot 2^3=64\) pure strategies.

The full normal-form payoff matrix is therefore \(27\times 64\).


  
  ## Step 2. Dominance elimination
  
  We now remove dominated actions card-by-card.

### Player 1

1. **Never fold \(A\).**  
  Calling with \(A\) guarantees winning any called pot; folding yields \(-1\).  
Hence \(s_1(A)=F\) is strictly dominated by \(s_1(A)=C\).

2. **Never call with \(Q\).**  
  Calling with \(Q\) always loses a called pot (net \(-3\)), while folding loses only \(-1\).  
Hence \(s_1(Q)=C\) is strictly dominated by \(s_1(Q)=F\).

After these eliminations:
  \[
    s_1(Q)\in\{B,F\},\qquad
    s_1(K)\in\{B,C,F\},\qquad
    s_1(A)\in\{B,C\}.
    \]
Player 1 now has
\[
  2\cdot 3\cdot 2 = 12
  \]
remaining strategies.


  
  ### Player 2
  
  1. **Never call with \(Q\).**  
  Calling always loses the called pot; folding dominates.

2. **Never check with \(A\) after a check.**  
  Betting weakly increases payoff in all contingencies and strictly increases it whenever called.

3. **Never bet with \(K\) after a check.**  
  Betting \(K\) risks being called only by \(A\) while failing to fold out \(A\); checking weakly dominates betting.

After these eliminations, Player 2’s remaining freedom is:
  
  - \(r_2(K)\in\{\text{Call},\text{Fold}\}\),
- \(a_2(Q)\in\{\text{Bet},\text{Check}\}\),

while the remaining components are fixed:
  \[
    r_2(Q)=\text{Fold},\qquad
    a_2(A)=\text{Bet},\qquad
    a_2(K)=\text{Check}.
    \]

Thus Player 2 has \(2\cdot 2=4\) remaining strategies.

The payoff matrix has been reduced from \(27\times 64\) to
\[
  12\times 4.
  \]


  
  ## Step 3. Further elimination
  
  Computing the resulting \(12\times 4\) payoff matrix and comparing rows reveals that only four Player 1 strategies are undominated:
  
  \[
    (F,C,B),\quad
    (F,C,C),\quad
    (F,F,B),\quad
    (F,F,C).
    \]

Restricting to these rows and re-evaluating the columns shows that “call with \(K\)” is dominated by “fold with \(K\).”  

The game therefore reduces to the following \(4\times 2\) payoff matrix:
  
  \[
    \begin{array}{c|cc}
    & (r_K=\text{Fold},\,a_Q=\text{Bet})
    & (r_K=\text{Fold},\,a_Q=\text{Check}) \\ \hline
    (F,C,B) & 0 & -\tfrac13 \\
    (F,C,C) & \tfrac13 & -\tfrac13 \\
    (F,F,B) & -\tfrac13 & 0 \\
    (F,F,C) & 0 & 0
    \end{array}
    \]

All entries are expected net payoffs to Player 1.


  
  ## Interpretation
  
  A sequential game that initially generated a \(27\times 64\) normal form has, through systematic dominance elimination, collapsed to a \(4\times 2\) matrix.

This reduction reveals structure:
  
  - With the bottom card, both players behave defensively.
- With the top card, betting after a check is forced by dominance.
- The strategic tension concentrates entirely in how the middle card is played.

At this point, the minimax analysis becomes transparent. The next subsection determines the value of the game and identifies its saddle point.

### 3.X+1  Minimax Analysis of the Reduced Game

After dominance elimination, the sequential game has been reduced to the following \(4\times 2\) normal-form matrix. Entries are expected net payoffs to Player 1.

\[
  \begin{array}{c|cc}
  & (r_K=\text{Fold},\,a_Q=\text{Bet})
  & (r_K=\text{Fold},\,a_Q=\text{Check}) \\ \hline
  (F,C,B) & 0 & -\tfrac13 \\
  (F,C,C) & \tfrac13 & -\tfrac13 \\
  (F,F,B) & -\tfrac13 & 0 \\
  (F,F,C) & 0 & 0
  \end{array}
  \]

Here the rows are Player 1 strategies:
  
  - \(F\) = check–fold,
- \(C\) = check–call,
- \(B\) = bet,

listed in the order \((Q,K,A)\).

The two remaining Player 2 strategies are:
  
  - Column 1: fold with \(K\), bet with \(Q\);
- Column 2: fold with \(K\), check with \(Q\).

All other components of Player 2’s strategy were fixed by dominance.


  
  ## Pure maximin and minimax
  
  We compute the row minima (Player 1’s worst-case payoffs):
  
  \[
    \begin{aligned}
    (F,C,B) &: \min\{0,-\tfrac13\}=-\tfrac13, \\
    (F,C,C) &: \min\{\tfrac13,-\tfrac13\}=-\tfrac13, \\
    (F,F,B) &: \min\{-\tfrac13,0\}=-\tfrac13, \\
    (F,F,C) &: \min\{0,0\}=0.
    \end{aligned}
    \]

Hence Player 1’s **pure maximin value** is
\[
  \underline v
  =\max\{-\tfrac13,-\tfrac13,-\tfrac13,0\}
  =0,
  \]
achieved by the strategy
\[
  (F,F,C).
  \]

Next compute the column maxima (Player 2 anticipating Player 1’s best response):
  
  \[
    \begin{aligned}
    \text{Column 1} &: \max\{0,\tfrac13,-\tfrac13,0\}
    =\tfrac13, \\
    \text{Column 2} &: \max\{-\tfrac13,-\tfrac13,0,0\}
    =0.
    \end{aligned}
    \]

Thus Player 2’s **pure minimax value** is
\[
  \overline v
  =\min\{\tfrac13,0\}
  =0,
  \]
achieved by Column 2.

Since
\[
  \underline v=\overline v=0,
  \]
a pure-strategy saddle point exists.


  
  ## The Saddle Point
  
  The saddle point occurs at the entry

\[
  \bigl((F,F,C),\ (r_K=\text{Fold},\,a_Q=\text{Check})\bigr),
  \]
with value \(0\).

### Interpreting the equilibrium strategies

**Player 1: \((F,F,C)\)**  
  - With \(Q\): check–fold.  
- With \(K\): check–fold.  
- With \(A\): check–call.

**Player 2:**  
  - After a check: bet with \(A\), check with \(K\), check with \(Q\).  
- Facing a bet: fold with \(Q\), fold with \(K\), (call with \(A\), by symmetry of dominance).

Under this profile:
  
  - Whenever Player 2 holds \(A\), they bet and Player 1 folds unless also holding \(A\), which is impossible.
- Otherwise the hand goes to showdown for a pot of 2.

A direct enumeration of the six equally likely deals shows that Player 1 wins exactly half the time and loses half the time, so the expected payoff is \(0\).


  
  ## Structural Interpretation
  
  Several features are noteworthy.

1. **Aggression concentrates at the top of the distribution.**  
  After dominance elimination, betting occurs only with the highest card.

2. **The middle card becomes strategically passive.**  
  Once dominated behaviors are removed, neither player benefits from escalating with \(K\).

3. **The value is zero without mixed strategies.**  
  Unlike many poker-style models, this extended sequential structure admits a pure saddle point after dominance reduction.

This example illustrates an important methodological lesson:  
  a sequential zero–sum game may generate a large normal-form matrix, but careful dominance analysis can reveal a small core game in which the minimax structure becomes transparent.




## Liberal Arts Sidebar  
### War, Games, and Human Cost  

**Lens:** History / Ethics  
**Theme:** Game theory’s military development and the moral risks of zero–sum framing  

Modern game theory is often introduced through poker or sports. Historically, however, its most influential applications emerged in the shadow of nuclear war.

In 1944, :contentReference[oaicite:0]{index=0} and :contentReference[oaicite:1]{index=1} published *Theory of Games and Economic Behavior*, formalizing strategic reasoning for adversarial settings. Within a decade, these ideas were being developed aggressively at the :contentReference[oaicite:2]{index=2}, where mathematicians, economists, and physicists were tasked with modeling nuclear deterrence.

### Cold War Strategy and Zero–Sum Models

The central strategic problem of the early Cold War was deterrence: how could two nuclear powers prevent one another from initiating a first strike?

Analysts modeled this as a two-player zero–sum game:

- Player I: the United States  
- Player II: the Soviet Union  

Each could choose levels of armament, targeting doctrines, or launch postures. Payoffs represented strategic advantage or vulnerability.

A simplified version of the logic was:

- If one side disarmed, it risked catastrophic loss.
- If one side struck first, the other might retaliate.
- If both retained second-strike capability, mutual destruction deterred aggression.

The resulting equilibrium concept — later described as “mutually assured destruction” — resembled minimax reasoning: each side sought to minimize the worst possible outcome imposed by the other.

Game-theoretic reasoning also shaped escalation theory. :contentReference[oaicite:3]{index=3} introduced models of credible commitment, brinkmanship, and strategic signaling. He emphasized that power often lay not in maximizing immediate payoff, but in manipulating an opponent’s expectations.

Nuclear strategy was therefore not merely about weapons. It was about incentives, beliefs, and equilibrium stability.

### Formal Models in Practice

Several concrete strategic tools emerged:

- **Second-strike capability models:** ensuring survivable retaliatory forces to maintain deterrence.
- **Arms race models:** analyzing whether increasing weapon stockpiles improved security or reduced it.
- **Crisis bargaining models:** predicting behavior during standoffs such as the Cuban Missile Crisis.

In each case, the underlying structure often assumed strict opposition:

$$
u_1 + u_2 = 0.
$$

One state’s strategic gain was modeled as the other’s loss.

### Contemporary Military Planning

Game-theoretic methods remain embedded in modern defense planning.

Applications include:

- Missile defense allocation models  
- Cybersecurity response games  
- Drone swarm and autonomous systems coordination  
- Strategic simulations of regional conflicts  

Military planners use computational game-theoretic models to evaluate adversarial adaptation. War games — both tabletop and computational — simulate multi-stage strategic interaction under uncertainty.

Today’s models are often more complex than early Cold War formulations. They incorporate incomplete information, signaling, repeated interaction, and probabilistic outcomes. Yet the adversarial core frequently retains a zero–sum structure.

### The Ethical Tension

Mathematically, zero–sum framing offers clarity. It sharpens incentives and produces equilibrium predictions. But the abstraction can obscure critical dimensions.

When nuclear strategy is modeled as a payoff matrix, “loss” may represent millions of lives. When cyberwarfare is modeled as optimization, civilian infrastructure may become a variable.

A zero–sum lens highlights conflict but suppresses shared vulnerability. During the Cold War, arms control agreements such as the Strategic Arms Limitation Talks (SALT) reflected recognition that some strategic interactions were not purely zero–sum. Cooperation could reduce mutual risk.

The mathematics of zero–sum games is precise. The moral landscape it describes is not.

### A Reflective Question

Game theory helps clarify strategic stability. But it also shapes how conflicts are conceptualized.

> When does zero–sum reasoning illuminate reality?  
> When does it risk narrowing moral imagination or obscuring the possibility of shared survival?

The power of mathematical modeling lies not only in what it reveals, but in what it leaves out.

## Homework Problems

### Conceptual Foundations
## Homework Problems

### I. Structural and Proof Problems

1. **Constant–Sum Games**

   (a) Prove that every constant–sum two–player game is strategically equivalent to a zero–sum game.

   (b) Show explicitly how to transform the payoff matrix
   $$
   A =
   \begin{pmatrix}
   2 & 5 \\
   7 & 1
   \end{pmatrix}
   $$
   into a zero–sum representation.



2. **Saddle Points and Mixed Strategies**

   Prove that if a saddle point exists in a finite two–player zero–sum game, then the corresponding pure strategy pair remains an equilibrium after allowing mixed strategies.



3. **Maximin Inequality**

   Prove that for every real matrix $A$,
   $$
   \max_i \min_j A_{ij}
   \;\le\;
   \min_j \max_i A_{ij}.
   $$

   (a) When does equality hold?  
   (b) Show that equality holds if and only if a saddle point exists.



4. **Indifference Principle (Proof)**

   Let $(x^*, y^*)$ be optimal mixed strategies in a finite zero–sum game with value $v$.

   Prove that if $x_i^* > 0$, then
   $$
   (A y^*)_i = v.
   $$


5.  **Crossed Saddle Points** Let $A$ be the payoff matrix of a finite two–player zero–sum game (payoff to the row player).

Suppose that $(i_a, j_a)$ and $(i_b, j_b)$ are saddle points. Denote the saddle value by
$$
v = A_{i_a j_a} = A_{i_b j_b}.
$$

Recall that $(i^*, j^*)$ is a saddle point if and only if
$$
A_{i j^*} \le A_{i^* j^*} \le A_{i^* j}
\quad \text{for all } i,j.
$$

1. Prove that
   $$
   A_{i_a j_b} = v
   \qquad\text{and}\qquad
   A_{i_b j_a} = v.
   $$

2. Prove that both $(i_a, j_b)$ and $(i_b, j_a)$ are themselves saddle points.

Your proof must rely only on the defining inequalities of a saddle point and should explicitly indicate where each inequality is used.


6. **Rectangular Structure of Pure Equilibria**

Let $A$ be the payoff matrix of a finite two–player zero–sum game.  
Suppose the game has at least two distinct saddle points.

Define
$$
R^* = \{\, i : \exists j \text{ such that } (i,j) \text{ is a saddle point} \,\},
$$
$$
C^* = \{\, j : \exists i \text{ such that } (i,j) \text{ is a saddle point} \,\}.
$$

Let $v$ denote the value of the game.

1. Prove that for every $i \in R^*$ and every $j \in C^*$,
   $$
   A_{ij} = v.
   $$

2. Conclude that every pair in
   $$
   R^* \times C^*
   $$
   is a saddle point.

3. In complete sentences, explain why this result implies that whenever a zero–sum game has more than one pure–strategy equilibrium, the set of equilibria must form a rectangular block in the payoff matrix.

Your explanation should carefully distinguish between:

- equality of payoff values, and  
- equilibrium (best–response) structure.

7. **Uniqueness of the Game Value**

   Prove that although optimal mixed strategies may not be unique, the value $v$ of a finite zero–sum game is unique.



### II. Computational Problems (Matrix Games)

8. **A $2\times2$ Bluffing Game**

   Consider the payoff matrix
   $$
   A =
   \begin{pmatrix}
   2 & -1 \\
   -2 & 1
   \end{pmatrix}.
   $$

   (a) Show that no pure saddle point exists.  
   (b) Compute the optimal mixed strategies.  
   (c) Verify the indifference principle directly.  
   (d) Compute the value of the game.



9. **Dominated Strategies**

   Consider the matrix
   $$
   A =
   \begin{pmatrix}
   3 & 1 & 2 \\
   2 & 0 & 1 \\
   4 & 2 & 3
   \end{pmatrix}.
   $$

   (a) Identify all strictly or weakly dominated strategies.  
   (b) Reduce the matrix.  
   (c) Determine whether a saddle point exists.



### III. The Three–Card Poker Game

In this section, refer to the simultaneous three-card poker model from the chapter:

- Deck $\{A,K,Q\}$,
- Both players simultaneously choose Bet or Not,
- Payoffs:
  - Both check → high card wins $+1$,
  - One bets → bettor wins $+1$,
  - Both bet → high card wins $+2$.

After eliminating dominated strategies, each player has four pure strategies:
$$
BNN,\ BNB,\ BBN,\ BBB.
$$



10. **Reduced Payoff Matrix**

   (a) Write down the reduced $4 \times 4$ payoff matrix explicitly.

   (b) Verify directly that no saddle point exists.

   (c) Compute
   $$
   \max_i \min_j A_{ij}
   \quad\text{and}\quad
   \min_j \max_i A_{ij}.
   $$



11. **Behavioral Parameterization**

   Let
   $$
   \alpha = \Pr(\text{bet with } K), 
   \qquad
   \beta = \Pr(\text{bet with } Q).
   $$

   (a) Derive the expected payoff
   $$
   u(\alpha,\beta;\gamma,\delta)
   $$
   in terms of the opponent’s parameters $(\gamma,\delta)$.

   (b) Show explicitly that $u$ is bilinear.



12. **Solving the Poker Equilibrium**

   Using the behavioral formulation:

   (a) Derive the indifference condition that determines the equilibrium bluffing frequency.

   (b) Solve explicitly for the equilibrium frequencies.

   (c) Compute the value of the game.

   (d) Explain in words why bluffing must occur but not too frequently.



13. **Stability**

   Suppose Player I bluffs with $Q$ at frequency $\beta > \beta^*$.

   (a) Show that Player II can exploit this deviation.

   (b) Compute Player I’s loss from over-bluffing.



### IV. Geometry and Structure

14. **Convexity**

   Let $f(x,y) = x^T A y$.

   (a) Prove that $f$ is linear in $x$ for fixed $y$.

   (b) Show that
   $$
   \min_y f(x,y)
   $$
   is a concave function of $x$.

   (c) Explain why this concavity is relevant for equilibrium existence.



15. **Degenerate Equilibria**

   Construct a $2\times2$ zero–sum matrix game with infinitely many mixed equilibria.

   Explain why this does not contradict the minimax theorem.



### V. Conceptual and Modeling Questions

16. **When Is Randomization Necessary?**

   Provide a precise mathematical condition under which a finite two–player zero–sum game requires mixed strategies (i.e., has no pure saddle point).

   Illustrate your answer with a poker-inspired matrix.



17. **Zero–Sum Modeling**

   Is cash-game poker strictly zero–sum? What about tournament poker?  How do these variations differ?

   Consider:

   - Rake,
   - Entry fees,
   - External rewards.

   Provide a mathematical argument analyzing whether the zero–sum assumption holds.

## Extension Activity

Extend the chapter’s main tool using a small simulation or a short written reflection connecting poker to another domain.


